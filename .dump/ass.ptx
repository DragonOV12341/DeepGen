//
// Generated by LLVM NVPTX Back-End
//

.version 8.0
.target sm_90a
.address_size 64

	// .globl	kernel
.extern .shared .align 1024 .b8 smem[];

.visible .entry kernel(
	.param .align 64 .b8 kernel_param_0[128],
	.param .align 64 .b8 kernel_param_1[128],
	.param .align 64 .b8 kernel_param_2[128]
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<290>;
	.reg .b64 	%rd<19>;

	mov.b64 	%rd4, kernel_param_0;
	mov.b64 	%rd5, kernel_param_1;
	mov.b64 	%rd6, kernel_param_2;
	cvta.param.u64 	%rd10, %rd6;
	cvta.param.u64 	%rd8, %rd5;
	cvta.param.u64 	%rd7, %rd4;
	mov.u32 	%r75, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	setp.ne.b32 	%p1, %r2, 0;
	@%p1 bra 	$L__BB0_2;
	prefetch.tensormap [%rd7];
	prefetch.tensormap [%rd8];
	prefetch.tensormap [%rd10];
$L__BB0_2:
	and.b32 	%r76, %r75, 31;
	shl.b32 	%r77, %r75, 2;
	bar.warp.sync 	-1;
	@%p1 bra 	$L__BB0_4;
	mov.b32 	%r78, 1;
	mbarrier.init.shared.b64 	[smem+40960], %r78;
	fence.proxy.async.shared::cta;
$L__BB0_4:
	mov.u32 	%r1, %warpid;
	mov.u32 	%r3, %laneid;
	shr.u32 	%r4, %r2, 7;
	and.b32 	%r172, %r77, -128;
	shl.b32 	%r173, %r76, 7;
	bar.sync 	0;
	mov.b32 	%r256, 0;
	mov.b32 	%r257, %r256;
	mov.b32 	%r258, %r256;
	mov.b32 	%r259, %r256;
	mov.b32 	%r260, %r256;
	mov.b32 	%r261, %r256;
	mov.b32 	%r262, %r256;
	mov.b32 	%r263, %r256;
	mov.b32 	%r264, %r256;
	mov.b32 	%r265, %r256;
	mov.b32 	%r266, %r256;
	mov.b32 	%r267, %r256;
	mov.b32 	%r268, %r256;
	mov.b32 	%r269, %r256;
	mov.b32 	%r270, %r256;
	mov.b32 	%r271, %r256;
	mov.b32 	%r272, %r256;
	mov.b32 	%r273, %r256;
	mov.b32 	%r274, %r256;
	mov.b32 	%r275, %r256;
	mov.b32 	%r276, %r256;
	mov.b32 	%r277, %r256;
	mov.b32 	%r278, %r256;
	mov.b32 	%r279, %r256;
	mov.b32 	%r280, %r256;
	mov.b32 	%r281, %r256;
	mov.b32 	%r282, %r256;
	mov.b32 	%r283, %r256;
	mov.b32 	%r284, %r256;
	mov.b32 	%r285, %r256;
	mov.b32 	%r286, %r256;
	mov.b32 	%r287, %r256;
	mov.b32 	%r288, %r256;
	mov.b32 	%r289, %r256;
	bra.uni 	$L__BB0_5;
$L__BB0_8:
	and.b32 	%r185, %r256, 1;
	mov.b32 	%r250, smem;
	add.s32 	%r184, %r250, 40960;
	{
	.reg .pred       P1; 
	LAB_WAIT: 
	mbarrier.try_wait.parity.shared.b64 P1, [%r184], %r185, 10000000; 
	@P1 bra.uni DONE; 
	bra.uni     LAB_WAIT; 
	DONE: 
	}
	wgmma.fence.sync.aligned;
	shl.b32 	%r251, %r4, 11;
	add.s32 	%r252, %r250, %r251;
	shr.u32 	%r253, %r252, 4;
	cvt.u64.u32 	%rd15, %r253;
	and.b64 	%rd16, %rd15, 16383;
	or.b64 	%rd13, %rd16, 4611686018427387904;
	add.s32 	%r254, %r250, 4096;
	shr.u32 	%r255, %r254, 4;
	cvt.u64.u32 	%rd17, %r255;
	and.b64 	%rd18, %rd17, 16383;
	or.b64 	%rd14, %rd18, 4611686018427387904;
	{
.reg .pred p;
setp.ne.b32 p, 1, 0;
wgmma.mma_async.sync.aligned.m64n128k16.f16.f16.f16 {%r258, %r259, %r260, %r261, %r262, %r263, %r264, %r265, %r266, %r267, %r268, %r269, %r270, %r271, %r272, %r273, %r274, %r275, %r276, %r277, %r278, %r279, %r280, %r281, %r282, %r283, %r284, %r285, %r286, %r287, %r288, %r289}, %rd13, %rd14, p, 1,  1, 0,  1;
}

	wgmma.commit_group.sync.aligned;
	wgmma.wait_group.sync.aligned 	0;
	add.s32 	%r257, %r257, 16;
	add.s32 	%r256, %r256, 1;
$L__BB0_5:
	setp.gt.s32 	%p3, %r257, 4095;
	@%p3 bra 	$L__BB0_9;
	@%p1 bra 	$L__BB0_8;
	mov.b32 	%r175, smem;
	add.s32 	%r178, %r175, 40960;
	cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes.L2::cache_hint [%r175], [%rd7, {%r257,%r172} ], [%r178], 1152921504606846976;
	add.s32 	%r179, %r175, 4096;
	cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes.L2::cache_hint [%r179], [%rd8, {%r173,%r257} ], [%r178], 1152921504606846976;
	mbarrier.arrive.expect_tx.shared.b64 _, [%r178], 8192;
	bra.uni 	$L__BB0_8;
$L__BB0_9:
	bar.sync 	0;
	shr.s32 	%r152, %r1, 31;
	shr.u32 	%r153, %r152, 30;
	add.s32 	%r154, %r1, %r153;
	and.b32 	%r155, %r154, -4;
	sub.s32 	%r156, %r1, %r155;
	setp.lt.s32 	%p5, %r156, 0;
	add.s32 	%r157, %r156, 4;
	selp.b32 	%r158, %r157, %r156, %p5;
	and.b32 	%r159, %r3, 15;
	shl.b32 	%r160, %r4, 13;
	shl.b32 	%r161, %r158, 11;
	shl.b32 	%r162, %r159, 7;
	or.b32 	%r163, %r161, %r162;
	add.s32 	%r164, %r160, %r163;
	shr.u32 	%r165, %r3, 1;
	and.b32 	%r166, %r165, 8;
	or.b32 	%r167, %r164, %r166;
	shl.b32 	%r168, %r167, 1;
	mov.b32 	%r169, smem;
	add.s32 	%r170, %r169, %r168;
	add.s32 	%r112, %r170, 8192;
	stmatrix.sync.aligned.x4.m8n8.shared.b16 [%r112], {%r258, %r259, %r260, %r261};
	add.s32 	%r117, %r170, 8224;
	stmatrix.sync.aligned.x4.m8n8.shared.b16 [%r117], {%r262, %r263, %r264, %r265};
	add.s32 	%r122, %r170, 8256;
	stmatrix.sync.aligned.x4.m8n8.shared.b16 [%r122], {%r266, %r267, %r268, %r269};
	add.s32 	%r127, %r170, 8288;
	stmatrix.sync.aligned.x4.m8n8.shared.b16 [%r127], {%r270, %r271, %r272, %r273};
	add.s32 	%r132, %r170, 8320;
	stmatrix.sync.aligned.x4.m8n8.shared.b16 [%r132], {%r274, %r275, %r276, %r277};
	add.s32 	%r137, %r170, 8352;
	stmatrix.sync.aligned.x4.m8n8.shared.b16 [%r137], {%r278, %r279, %r280, %r281};
	add.s32 	%r142, %r170, 8384;
	stmatrix.sync.aligned.x4.m8n8.shared.b16 [%r142], {%r282, %r283, %r284, %r285};
	add.s32 	%r147, %r170, 8416;
	stmatrix.sync.aligned.x4.m8n8.shared.b16 [%r147], {%r286, %r287, %r288, %r289};
	fence.proxy.async.shared::cta;
	bar.sync 	0;
	@%p1 bra 	$L__BB0_11;
	add.s32 	%r171, %r169, 8192;
	cp.async.bulk.tensor.2d.global.shared::cta.bulk_group [%rd10, {%r172, %r173} ], [%r171];
	cp.async.bulk.commit_group;
$L__BB0_11:
	bar.warp.sync 	-1;
	ret;

}

